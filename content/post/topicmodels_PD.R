In this project, I followed [topic modelling chapter](https://www.tidytextmining.com/topicmodeling.html) in the "Text Mining with R" book which used the R package `topicmodels`. This chapter not only provides how to do topic modelling, but also a brief explanation on Latent Dirichlet allocation, the most common algorithm used for topic modelling. This algorithm was implemented in `topicmodels::LDA` function.

As I assume evolutionary concept will be the main discussion on the papers besides the conservation part, I assume that the papers will be separated into two topics. 

```{r tidyText}
library(topicmodels)
corpus_pd_lda<-LDA(corpus_pd_dtm, k=2, control=list(seed=1234)) # a LDA model with 2 topics
corpus_pd_topics<-tidy(corpus_pd_lda, matrix="beta") # tidying the LDA model
corpus_pd_topics
```

This tibble data format showed that in the two topics I assigned, there were a 0.00518 probability that the word ''0'' was being generated from topic 1 and 0.00139 for topic 2. We will use dplyr to see the word with highest probability generated

```{r }
library(ggplot2)
library(dplyr)

pd_top_terms<-corpus_pd_topics %>% group_by(topic) %>% top_n(10,beta) %>% ungroup() %>% arrange(topic, beta)
pd_top_terms %>% mutate(term=reorder(term, beta)) %>% 
  ggplot(aes(term,beta,fill=factor(topic))) + 
  geom_col(show.legend = F) + 
  facet_wrap(~topic, scales="free") +
  coord_flip()
```

There were several things interesting from this result. First of all, the papers are all about phylogenetic diversity of species. Of course the three terms will be the most commonly used. Another thing is ``25cf`` as the most common term in topic 1; what is this? After I googled this term, this is an unicode character for black circle, which apparently used a lot in the papers for their graphs. Similar also is ''fb01'' in topic 2 which is a latin small ligature fi. These terms apparently came when we parsed the pdf files into characters. The font type and typography of each papers are different and it seemed that most of them enable the letter 'f' and 'i' read together as a glyph. The term 'al' was apparently from 'et al' which is really a lot in scientific literature. I assume that the 'et' was already removed by the stop_words argument when I was tidying the corpus as it was similar with 'and'.

Naturally, we would like to clean such terms to really get the topics. We could assign additional stop words for this and then re-run the previous code.

```{r cleanTidy}
stop_words_pd<-tibble(word=c(as.character(seq(0,9,1)),"phylogenetic", "diversity", "species","25cf","al","fb01"), lexicon="PD")
corpus_pd_dtm<-corpus_pd %>% 
  unnest_tokens(word,content) %>% 
  anti_join(stop_words) %>% 
  anti_join(stop_words_pd) %>% 
  
  count(title, word) %>% 
  cast_dtm(title, word, n)
corpus_pd_lda<-LDA(corpus_pd_dtm, k=2, control=list(seed=1234)) # a LDA model with 2 topics
corpus_pd_topics<-tidy(corpus_pd_lda, matrix="beta") # tidying the LDA model
pd_top_terms<-corpus_pd_topics %>% group_by(topic) %>% top_n(10,beta) %>% ungroup() %>% arrange(topic, beta)
pd_top_terms %>% mutate(term=reorder(term, beta)) %>% 
  ggplot(aes(term,beta,fill=factor(topic))) + 
  geom_col(show.legend = F) + 
  facet_wrap(~topic, scales="free") +
  coord_flip()

```

From this second graph, now we get that the two topics indeed talking two different concepts: topic 1 talks more about conservation and richness, along with data, while topic 2 are more into community structure and its relation to environment. Evolution was not seemed to be a concept that was talked about in the phylogenetic diversity research!
  
  Note that there are words that are having a high probability generated by the two topics: ''ecology''. We could investigate further such terms by seeking how likely is the this word being generated by topic 1 rather than topic 2. I did this by estimating the log ratio of the two as log give symmetrical differences between the two. To constrain it to a set of especially relevant words, we can filter for relatively common words, such as those that have a %\beta$ greater than 1/1000 in at least one topic.

```{r greatestBeta}
library(tidyr)

beta_spread <- corpus_pd_topics %>% 
  mutate(topic = paste0("topic", topic)) %>%
  spread(topic, beta) %>%
  filter(topic1 > .001 | topic2 > .001) %>%
  mutate(log_ratio = log2(topic2 / topic1))
beta_spread
```

Interestingly, there are ''words'' that are numbers. Although this does not give us many about the concepts in theoretical sense, it showed us the state of scientific practices that heavily depends on p-values (I think this is where ''0.001'' came from). Others are the years, which could be years of the papers' publication or also years of the cited reference. The terms with the greatest difference could be visualized as follows.

```{r visualizeDiff}
beta_spread %>% mutate(term=reorder(term, log_ratio)) %>% 
ggplot(aes(x=term,y=log_ratio)) + 
geom_col(show.legend=F) +
labs(y="Log2 ratio of topic 2 / topic 1")+
coord_flip()
```

As you can see, we have hundreds of terms that are having higher probability being generated by one of the topics to different degrees. We could try ''zooming in'' to top 15 terms for each topics to further understand what the topics are about.

```{r diffTopic1, fig.cap="Top terms for Topic 2"}
beta_spread %>% mutate(term=reorder(term, log_ratio)) %>% top_n(20,log_ratio) %>% 
ggplot(aes(x=term,y=log_ratio)) + 
geom_col(show.legend=F) +
labs(y="Log2 ratio of topic 2 / topic 1")+
coord_flip()
```

When the log ratio were positive, or the terms are mostly related to topic 2, we got words related to the community assembly processes such as ''similarity'', ''relatedness'', ''competition'', or even ''assembly'' itself. The large difference in the word ''plot'' is probably because such topic often study plants, sampled from various plots, and oftentimes also investigated along its beta diversity.

```{r diffTopic2}
beta_spread %>% mutate(term=reorder(term, log_ratio)) %>% top_n(-20,log_ratio) %>% 
ggplot(aes(x=term,y=log_ratio)) + 
geom_col(show.legend=F) +
labs(y="Log2 ratio of topic 2 / topic 1")+
coord_flip()
```

In Topic 1, most terms were related to biodiversity conservation (because of the term ''land'', ''human'', ''endemism'', 'loss'') or animal morphology (because of the term ''wing''. ''fish'', ''serpentine''). The large difference of ''serpentine'' is probably related to the paper about it that focuses in the taxa's conservation. 

We should note that the log2 ratio in the terms with negative log ratio tend to have values closer to zero than the terms with positive log ratio. This could mean that although the topics differ in the tendency of word choice, some words are used quite frequently in both topics. This is probably why the word ''ecology'' is not seen in both top 15 terms; it was used equally frequent in both topics.

We now of course wondered which documents are talking about these topics? To do that, we could use the following code.

```{r documentMatrix}
pd_documents<-tidy(corpus_pd_lda, matrix="gamma")
pd_documents
```

Each of these values is an estimated proportion of words from that document that are generated from that topic. For example, the model estimates that ~87% of the words in the first document were generated from topic 1.
