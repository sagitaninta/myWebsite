top_n(15,beta) %>%
ungroup() %>%
arrange(topic, beta) %>%
mutate(term=reorder(term, beta)) %>%
ggplot(aes(reorder(term,-beta),beta,fill=factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~topic, scales="free")
corpus_pd_topics %>%
group_by(topic) %>%
top_n(15,beta) %>%
ungroup() %>%
arrange(topic, beta) %>%
mutate(term=reorder(term, beta)) %>%
ggplot(aes(reorder(term,beta),beta,fill=factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~topic, scales="free")
corpus_pd_topics %>%
group_by(topic) %>%
top_n(15,beta) %>%
ungroup() %>%
arrange(topic, beta) %>%
mutate(term=reorder(term, beta)) %>%
ggplot(aes(reorder(term,-beta),beta,fill=factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~topic, scales="free")
corpus_pd_topics %>%
group_by(topic) %>%
top_n(15,beta) %>%
ungroup() %>%
arrange(topic, beta) %>%
mutate(term=reorder(term, beta)) %>%
ggplot(aes(term,beta,fill=factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~topic, scales="free")
corpus_pd_topics %>%
group_by(topic) %>%
top_n(15,beta) %>%
ungroup() %>%
arrange(topic, beta) %>%
mutate(term=reorder(term, -beta)) %>%
ggplot(aes(term,beta,fill=factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~topic, scales="free")
corpus_pd_topics %>%
group_by(topic) %>%
top_n(15,beta) %>%
ungroup() %>%
arrange(topic, beta) %>%
mutate(term=reorder(term, -beta)) %>%
ggplot(aes(term,beta,fill=factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~topic, scales="free") +
coord_flip()
corpus_pd_topics %>%
group_by(topic) %>%
top_n(15,beta) %>%
ungroup() %>%
arrange(topic, beta) %>%
mutate(term=reorder(term, beta)) %>%
ggplot(aes(term,beta,fill=factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~topic, scales="free") +
coord_flip()
corpus_pd_topics %>%
group_by(topic) %>%
top_n(15,beta) %>%
ungroup() %>%
arrange(topic, beta) %>%
mutate(term=reorder(term, beta)) %>%
ggplot(aes(term,beta,fill=factor(topic))) +
geom_col(show.legend = F) +
#  facet_wrap(~topic, scales="free") +
coord_flip()
corpus_pd_topics %>%
group_by(topic) %>%
top_n(15,beta) %>%
ungroup() %>%
arrange(topic, beta) %>%
mutate(term=reorder(term, beta)) %>%
ggplot(aes(term,beta,fill=factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~topic, scales="free") +
coord_flip()
corpus_pd_topics %>%
group_by(topic) %>%
top_n(15,beta) %>%
ungroup() %>%
arrange(topic, beta) %>%
mutate(term=reorder(term, beta)) %>%
ggplot(aes(term,beta,fill=factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~topic) +
coord_flip()
corpus_pd_topics %>%
group_by(topic) %>%
top_n(10,beta) %>%
ungroup() %>%
arrange(topic, beta) %>%
mutate(term=reorder(term, beta)) %>%
ggplot(aes(term,beta,fill=factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~topic) +
coord_flip()
corpus_pd_topics %>%
group_by(topic) %>%
top_n(5,beta) %>%
ungroup() %>%
arrange(topic, beta) %>%
mutate(term=reorder(term, beta)) %>%
ggplot(aes(term,beta,fill=factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~topic) +
coord_flip()
corpus_pd_topics %>%
group_by(topic) %>%
top_n(5,beta) %>%
ungroup() %>%
arrange(topic, beta) %>%
mutate(term=reorder(term, beta)) %>%
ggplot(aes(term,beta,fill=factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~topic, scales = "free") +
coord_flip()
corpus_pd_topics %>%
group_by(topic) %>%
top_n(7,beta) %>%
ungroup() %>%
arrange(topic, beta) %>%
mutate(term=reorder(term, beta)) %>%
ggplot(aes(term,beta,fill=factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~topic, scales = "free") +
coord_flip()
corpus_pd_topics %>%
group_by(topic) %>%
top_n(10,beta) %>%
ungroup() %>%
arrange(topic, beta) %>%
mutate(term=reorder(term, beta)) %>%
ggplot(aes(term,beta,fill=factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~topic, scales = "free") +
coord_flip()
corpus_pd_topics %>%
group_by(topic) %>%
top_n(15,beta) %>%
ungroup() %>%
arrange(topic, beta) %>%
mutate(term=reorder(term, beta)) %>%
ggplot(aes(term,beta,fill=factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~topic, scales = "free") +
coord_flip()
pd_stm<-readCorpus(corpus_pd_dtm, type="slam")
pd_stm_out<-prepDocuments(pd_stm$documents, pd_stm$vocab, lower.thresh = 5)
pd_stm<-stm(corpus_stm_out$documents, corpus_stm_out$vocab, k=4)
rm(pd_stm,pd_stm_out)
corpus_stm<-readCorpus(corpus_pd_dtm, type="slam")
corpus_stm_out<-prepDocuments(corpus_stm$documents, corpus_stm$vocab, lower.thresh = 5)
pd_stm<-stm(corpus_stm_out$documents, corpus_stm_out$vocab, k=4)
pd_stm<-stm(corpus_stm_out$documents, corpus_stm_out$vocab, K=4)
pd_stm<-stm(corpus_stm_out$documents, corpus_stm_out$vocab, K=3)
labelTopics(pd_stm)
pd_stm<-stm(corpus_stm_out$documents, corpus_stm_out$vocab, K=4)
pd_stm<-stm(corpus_stm_out$documents, corpus_stm_out$vocab, K=5)
pd_stm<-stm(corpus_stm_out$documents, corpus_stm_out$vocab, K=6)
corpus_pd_lda<-LDA(corpus_pd_dtm, k=6, control=list(seed=1234)) # a LDA model with 5 topics
corpus_pd_topics<-tidy(corpus_pd_lda, matrix="beta") # tidying the LDA model
corpus_pd_topics %>%
group_by(topic) %>%
top_n(10,beta) %>%
ungroup() %>%
arrange(topic, beta) %>%
mutate(term=reorder(term, beta)) %>%
ggplot(aes(term,beta,fill=factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~topic, scales = "free") +
coord_flip()
labelTopics(pd_stm)
plot.STM(pd_stm,type = "labels")
thoughts5 <- findThoughts(pd_stm, topics = 5)
thoughts5
thoughts5 <- findThoughts(pd_stm, topics = 1)
thoughts5
plot.STM(pd_stm,type="perspectives",topics=c(5,4), xlim=c(1,25)) # Graphical Display of Topical Contrast
plot.STM(pd_stm,type="hist",topics=c(1,2,3), xlim=c(0,1))
cloud(pd_stm, topic=5)
plot.STM(pd_stm,type="summary", xlim=c(0,1)) # no differences in the three topics, they are highly related
mod.out.corr<-topicCorr(pd_stm)
plot.topicCorr(mod.out.corr)
install.packages("igraph")
plot.STM(pd_stm,type="summary", xlim=c(0,1)) # no differences in the three topics, they are highly related
plot.STM(pd_stm,type="hist", xlim=c(0,1))
plot.STM(pd_stm,type="perspectives",topics=c(5,4), xlim=c(1,25)) # Graphical Display of Topical Contrast
plot.STM(pd_stm,type="perspectives",topics=c(5,4), xlim=c(1,30)) # Graphical Display of Topical Contrast
plot.STM(pd_stm,type="perspectives",topics=c(5,4), xlim=c(1,50)) # Graphical Display of Topical Contrast
plot.STM(pd_stm,type = "labels")
labelTopics(pd_stm)
plot.STM(pd_stm,type = "labels")
?plot.STM
plot.STM(pd_stm,type="perspectives",topics=c(5,4), xlim=c(1,50)) # Graphical Display of Topical Contrast
plot.STM(pd_stm,type="perspectives",topics=c(5,4)) # Graphical Display of Topical Contrast
corpus_pd_topics %>%
group_by(topic) %>%
top_n(10,beta) %>%
ungroup() %>%
arrange(topic, beta) %>%
mutate(term=reorder_within(term, beta, title)) %>%
ggplot(aes(term,beta,fill=factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~topic, scales = "free") +
coord_flip()
library(tidytext)
corpus_pd_topics %>%
group_by(topic) %>%
top_n(10,beta) %>%
ungroup() %>%
arrange(topic, beta) %>%
mutate(term=reorder_within(term, beta, title)) %>%
ggplot(aes(term,beta,fill=factor(topic))) +
geom_col(show.legend = F) +
facet_wrap(~topic, scales = "free") +
coord_flip()
install.packages("drlib")
library(drlib)
devtools::install_github("juliasilge/tidytext")
devtools::install_github("juliasilge/tidytext")
install.packages(tidytext)
install.packages("tidytext")
library(tidytext)
corpus_pd_dtm <- corpus_pd %>%
unnest_tokens(word,content) %>%
anti_join(stop_words) %>% # until here you got tidytext format
filter(word != c("phylogenetic","species","diversity")) %>% # removing these words as they were too common and used neutrally in all papers
filter(!str_detect(word, "[:digit:]")) %>% # removing numbers as we don't need numbers
count(title, word) %>%
cast_dtm(title, word, n) # until here you got document-term-matrix format
library(dplyr)
corpus_pd_dtm <- corpus_pd %>%
unnest_tokens(word,content) %>%
anti_join(stop_words) %>% # until here you got tidytext format
filter(word != c("phylogenetic","species","diversity")) %>% # removing these words as they were too common and used neutrally in all papers
filter(!str_detect(word, "[:digit:]")) %>% # removing numbers as we don't need numbers
count(title, word) %>%
cast_dtm(title, word, n) # until here you got document-term-matrix format
?str_detect
library(tidyverse)
corpus_pd_dtm <- corpus_pd %>%
unnest_tokens(word,content) %>%
anti_join(stop_words) %>% # until here you got tidytext format
filter(word != c("phylogenetic","species","diversity")) %>% # removing these words as they were too common and used neutrally in all papers
filter(!str_detect(word, "[:digit:]")) %>% # removing numbers as we don't need the numbers for concept analysis
count(title, word) %>%
cast_dtm(title, word, n) # until here you got document-term-matrix format
corpus_pd_dtm # checking document-term-matrix format for topic modelling
corpus_pd_lda<-LDA(corpus_pd_dtm, k=2, control=list(seed=1234)) # a LDA model with 2 topics
corpus_pd_topics<-tidy(corpus_pd_lda, matrix="beta") # tidying the LDA model
library(topicmodels)
corpus_pd_lda<-LDA(corpus_pd_dtm, k=2, control=list(seed=1234)) # a LDA model with 2 topics
?LDA
corpus_pd_topics<-tidy(corpus_pd_lda, matrix="beta") # tidying the LDA model
rm(list=ls())
corpus_pd<-read.csv("corpus_pd.csv",stringsAsFactors = F)
library(tm)
read <- readPDF(control = list(text = "-layout"))
## Getting all my literature in my folder
file_dir<-c("D:/Master/Thesis/PhylogeneticDiversity/PD_as_response_var") # literature directory
file_vector<-list.files(file_dir) # list of file names
document <- Corpus(DirSource(file_dir), readerControl = list(reader = read))
doc <- content(document[[1]])
head(doc)
doc <- content(document[[2]])
head(doc)
doc <- content(document[[112]])
head(doc) ## checking the papers content
document
str(document)
## Tidying corpus
library(tidytext)
document_tidy<-tidy(document)
document_tidy
stop_words
library(dplyr)
library(tidytext)
library(tidytext)
library(tidyverse)
stop_words
stop_words_add <- tibble(word=c("phylogenetic","diversity","species","et","al"), lexicon="additional")
stop_words_add
corpus_pd_dfm <- corpus_pd %>%
unnest_tokens(word,text) %>%
anti_join(stop_words) %>% # until here you got tidytext format
anti_join(stop_words_add) %>% # removing these words as they were too common and used neutrally in all papers
filter(!str_detect(word, "[:digit:]")) %>% # removing numbers as we don't need the numbers for concept analysis
filter(!str_detect(word, "[[:punct:]]")) %>% # removing punctuations, if any
count(id, word) %>%
cast_dfm(id, word, n) # until here you got document-term-matrix format
head(corpus_pd)
corpus_pd<-read.csv("corpus_pd.csv",stringsAsFactors = F)
head(corpus_pd)
corpus_pd_dfm <- corpus_pd %>%
unnest_tokens(word,text) %>%
anti_join(stop_words) %>% # until here you got tidytext format
anti_join(stop_words_add) %>% # removing these words as they were too common and used neutrally in all papers
filter(!str_detect(word, "[:digit:]")) %>% # removing numbers as we don't need the numbers for concept analysis
filter(!str_detect(word, "[[:punct:]]")) %>% # removing punctuations, if any
count(id, word) %>%
cast_dfm(id, word, n) # until here you got document-term-matrix format
corpus_pd_dfm # checking document-term-matrix format for topic modelling
library(stm)
pd_stm<-stm(corpus_pd_dfm, K=6, init.type = "LDA", verbose = F, seed=1234)
## Inspecting topics
plot.STM(pd_stm,type = "labels")
library(SnowballC)
corpus_pd_dfm <- corpus_pd %>%
unnest_tokens(word,text) %>%
anti_join(stop_words) %>% # until here you got tidytext format
anti_join(stop_words_add) %>% # removing these words as they were too common and used neutrally in all papers
filter(!str_detect(word, "[:digit:]")) %>% # removing numbers as we don't need the numbers for concept analysis
filter(!str_detect(word, "[[:punct:]]")) %>% # removing punctuations, if any
mutate(word = wordStem(word)) %>%
count(id, word) %>%
cast_dfm(id, word, n) # until here you got document-term-matrix format
pd_stm<-stm(corpus_pd_dfm, K=6, init.type = "LDA", verbose = F, seed=1234)
# Inspecting topics
plot.STM(pd_stm,type = "labels")
words <- c("love", "loving", "lovingly", "loved", "lover", "lovely", "love")
hunspell_stem(words)
hunspell_analyze(words)
install.packages("hunspell")
library(hunspell)
words <- c("love", "loving", "lovingly", "loved", "lover", "lovely", "love")
hunspell_stem(words)
hunspell_analyze(words)
corpus_pd_dfm <- corpus_pd %>%
unnest_tokens(word,text) %>%
anti_join(stop_words) %>% # until here you got tidytext format
anti_join(stop_words_add) %>% # removing these words as they were too common and used neutrally in all papers
filter(!str_detect(word, "[:digit:]")) %>% # removing numbers as we don't need the numbers for concept analysis
filter(!str_detect(word, "[[:punct:]]")) %>% # removing punctuations, if any
mutate(word = hunspell_stem(word)) %>% # stemming words
count(id, word) %>%
cast_dfm(id, word, n) # until here you got document-term-matrix format
pd_beta<-tidy(pd_stm)
## getting reorder_within function
source("https://raw.githubusercontent.com/juliasilge/tidytext/master/R/reorder_within.R")
## plotting most frequent words
pd_beta %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
mutate(topic = paste0("Topic ", topic),
term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = as.factor(topic))) +
geom_col(alpha = 0.8, show.legend = FALSE) +
facet_wrap(~ topic, scales = "free_y") +
coord_flip() +
scale_x_reordered() +
labs(x = NULL, y = expression(beta),
title = "Highest word probabilities for each topic",
subtitle = "Different words are associated with different topics")
## Inspecting topics
plot.STM(pd_stm,type = "perspectives", topics=c(1,5))
## Inspecting topics
plot.STM(pd_stm,type = "perspectives", topics=c(3,4))
pd_gamma<-tidy(pd_stm, matrix="gamma", papers=id)
pd_gamma
pd_gamma<-tidy(pd_stm, matrix="gamma", document_names = id)
pd_gamma<-tidy(pd_stm, matrix="gamma", document_names = rownames(corpus_pd_dfm))
pd_gamma
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma))
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(gamma,document))
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma))
ggplot(pd_gamma, aes(gamma, fill = as.factor(topic))) +
geom_histogram(alpha = 0.8, show.legend = FALSE) +
facet_wrap(~ topic, ncol = 3) +
labs(title = "Distribution of document probabilities for each topic",
subtitle = "Each topic is associated with 1-3 stories",
y = "Number of stories", x = expression(gamma))
ggplot(pd_gamma, aes(gamma, fill = as.factor(topic))) +
geom_histogram(alpha = 0.8, show.legend = FALSE) +
facet_wrap(~ topic, ncol = 3) +
labs(title = "Distribution of document probabilities for each topic",
subtitle = "Each topic is associated with 5-10 papers",
y = "Number of papers", x = expression(gamma))
ggplot(pd_gamma, aes(gamma, fill = as.factor(topic))) +
geom_histogram(alpha = 0.8, show.legend = FALSE) +
facet_wrap(~ topic, ncol = 3) +
labs(title = "Distribution of document probabilities for each topic",
subtitle = "Each topic is associated with 5-10 papers",
y = "Number of papers", x = expression(gamma)) +
ylim(c(0,10))
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma))
?gamma
?reorder
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma,count))
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma))
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma,max))
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma)) %>% max(gamma)
pd_gamma %>% filter(topic==2) %>% mutate(document=order(document,gamma))
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma))
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma)) %>%
ggplot(aes(document,gamma)) +
geom_bar()
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma)) %>%
ggplot(aes(document,gamma)) +
geom_col()
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma)) %>%
ggplot(aes(document,gamma)) +
geom_col() +
ylim(c(0.75,1.0)) + # limiting the documents with high prob
coord_flip()
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma)) %>%
ggplot(aes(document,gamma)) +
geom_col() +
coord_cartesian(y=c(0.75,1.0)) + # limiting the documents with high prob
coord_flip()
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma)) %>%
ggplot(aes(document,gamma)) +
geom_col() +
coord_cartesian(y=c(0.75,1.0)) # limiting the documents with high prob
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma)) %>%
ggplot(aes(document,gamma)) +
geom_col() +
coord_flip() +
coord_cartesian(y=c(0.75,1.0)) # limiting the documents with high prob
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma)) %>% filter(gamma>0.75) %>%
ggplot(aes(document,gamma)) +
geom_col() +
coord_flip()
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma)) %>% filter(gamma>0.75) %>%
ggplot(aes(document,gamma)) +
geom_col() +
coord_cartesian(y=c(0.7,1.0)) +
coord_flip()
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma)) %>% filter(gamma>0.75) %>%
ggplot(aes(document,gamma)) +
geom_col() +
coord_cartesian(ylim=c(0.7,1.0)) +
coord_flip()
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma)) %>% filter(gamma>0.75) %>%
ggplot(aes(document,gamma)) +
geom_col() +
ylim(c(0.7,1.0)) +
coord_flip()
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma)) %>% filter(gamma>0.75) %>%
ggplot(aes(document,gamma)) +
geom_col() +
ylim(c(0.5,1.0)) +
coord_flip()
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma)) %>% filter(gamma>0.75) %>%
ggplot(aes(document,gamma)) +
geom_col() +
coord_flip()
pd_gamma %>% filter(topic==2) %>% mutate(document=reorder(document,gamma)) %>% filter(gamma>0.85) %>%
ggplot(aes(document,gamma)) +
geom_col() +
coord_flip()
View(corpus_pd)
View(document_tidy)
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
# Inspecting topics
par(mai=c(0,0,0,0))
plot.STM(pd_stm,type = "labels")
?par
# Inspecting topics
par(mai=c(0,0,0,0),mar=c(0,0,0,0))
plot.STM(pd_stm,type = "labels")
# Inspecting topics
par(mai=c(0,0,0,0),mar=c(0,0,0,0),oma=c(0,0,0,0))
plot.STM(pd_stm,type = "labels")
?stm
?plot.STM
plot.STM(pd_stm,type = "labels", width=100, mai=c(0,0,0,0))
plot.STM(pd_stm,type = "labels", width=100, mar=c(0,0,0,0))
plot.STM(pd_stm,type = "labels", width=100, oma=c(0,0,0,0))
plot.STM(pd_stm,type = "labels", width=100, oma=c(0,0,0,0), mar=c(0,2,0,2))
plot.STM(pd_stm,type = "labels", width=100, oma=c(0,0,0,0), mar=c(2,0,2,0))
plot.STM(pd_stm,type = "labels", width=100, oma=c(0,0,0,0), mai=c(2,0,2,0))
plot.STM(pd_stm,type = "labels", width=100, oma=c(0,0,0,0), mai=c(0,2,0,0))
plot.STM(pd_stm,type = "labels", width=100, oma=c(0,0,0,0), mai=c(0,0,0,0))
plot.STM(pd_stm,type = "labels", width=100, oma=c(0,0,0,0), mar=c(0,0,0,0))
plot.STM(pd_stm,type = "labels", width=120, oma=c(0,0,0,0), mar=c(0,0,0,0))
plot.STM(pd_stm,type = "labels", width=120, oma=c(0,0,0,0), mai=c(0,0,0,0))
plot.STM(pd_stm,type = "labels", width=120, oma=c(0,0,0,0))
?plar
# Inspecting topics
?par
servr::daemon_stop(1)
blogdown::serve_site()
servr::daemon(2)
servr::daemon_stop(2)
blogdown::serve_site()
servr::daemon_stop(3)
blogdown::hugo_version()
blogdown::update_hugo()
blogdown::hugo_version()
blogdown::serve_site()
servr::daemon_stop(4)
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
servr::daemon_stop(5)
servr::daemon_stop(6)
servr::daemon_stop(7)
blogdown::serve_site()
servr::daemon_stop(8)
blogdown::hugo_version()
blogdown::serve_site()
