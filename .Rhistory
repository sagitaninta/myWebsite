library(blogdown)
serve_site()
serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
servr::daemon_stop(1)
blogdown::serve_site()
servr::daemon_stop(2)
blogdown::serve_site()
servr::daemon_stop(3)
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
servr::daemon_stop(6)
servr::daemon_stop(7)
servr::daemon_stop(6)
installed.packages(dplyr)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
> installed.packages(dplyr)
installed.packages(dplyr)
installed.packages(dplyr)
installed.packages(blogdown)
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
~/.active-rstudio-document
installed.packages(dplyr)
installed.packages(dplyr)
installed.packages(dplyr)
installed.packages(ggplot2)
installed.packages(ggplot2)
installed.packages(dplyr)
library(dplyr)
install.packages("ggplot2")
library(dplyr)
install.packages("dplyr")
library(dplyr)
installed.packages(dplyr)
install.packages(c("backports", "broom", "data.table", "devtools", "network", "openssl", "quanteda", "remotes", "reticulate", "rJava", "RSpectra", "rvest", "sandwich", "tinytex", "usethis"))
dplyr::
install.packages("dplyr")
installed.packages(dplyr)
library(dplyr)
install.packages("tibble")
library(dplyr)
library(ggplot2)
install.packages("withr")
library(ggplot2)
.libPaths()
library(pdftools)
## Getting all my literature in my folder
file_vector<-list.files(path="D:\Master\Thesis\PhylogeneticDiversity\PD_as_response_var")
## Getting all my literature in my folder
file_vector<-list.files(path="D:/Master/Thesis/PhylogeneticDiversity/PD_as_response_var")
str(file_vector)
head(file_vector)
type(file_vector)
class(file_vector)
typeof(file_vector)
pd_text<-lapply(file_vector, pdf_text)
pd_text_1<-pdf_text(file_vector[1])
pd_text_1<-pdf_text(paste("D:/Master/Thesis/PhylogeneticDiversity/PD_as_response_var/",file_vector[1]))
pd_text_1<-pdf_text("D:/Master/Thesis/PhylogeneticDiversity/PD_as_response_var/03Harrison_CH03.pdf")
pd_text_1<-pdf_text(paste("D:/Master/Thesis/PhylogeneticDiversity/PD_as_response_var/03Harrison_CH03.pdf"))
file_vector[1]
pd_text_1<-pdf_text(paste("D:/Master/Thesis/PhylogeneticDiversity/PD_as_response_var/",file_vector[1]))
pd_text_1<-pdf_text(paste("D:/Master/Thesis/PhylogeneticDiversity/PD_as_response_var",file_vector[1]))
paste("D:/Master/Thesis/PhylogeneticDiversity/PD_as_response_var",file_vector[1]
paste("D:/Master/Thesis/PhylogeneticDiversity/PD_as_response_var",file_vector[1]
paste("D:/Master/Thesis/PhylogeneticDiversity/PD_as_response_var",file_vector[1])
?paste
paste("D:/Master/Thesis/PhylogeneticDiversity/PD_as_response_var/",file_vector[1], sep = "")
pd_text_1<-pdf_text(paste("D:/Master/Thesis/PhylogeneticDiversity/PD_as_response_var/",file_vector[1], sep = ""))
## Getting all my literature in my folder
file_dir<-c("D:/Master/Thesis/PhylogeneticDiversity/PD_as_response_var")
file_vector<-list.files(path=file_dir)
pd_text_1<-pdf_text(paste(file_dir,"/",file_vector[1], sep = ""))
str(pd_text_1)
pd_text_1
library(tidyverse)
pd_text_1 %>% strsplit()
pd_text_1 %>% strsplit(split = "\n")
# is it the same for every pdf?
pd_text_2<-pdf_text(paste(file_dir,"/",file_vector[2], sep = ""))
pd_text_2 %>% strsplit(split = "\n") # splitting the content to give our data a structure that is closer to the original one
pd_text_1[1]
pd_text_1[[1]]
pd_text_1[[1]][1]
str(pd_text_1)
pd_text_1<-pd_text_1 %>% strsplit(split = "\n") # splitting the content to give our data a structure that is closer to the original one
str(pd_text_1)
pd_text_1[[1]][1]
pd_text_1[[1]][2]
pd_text_1[[1]][3]
pd_text_1[[1]][4]
pd_text_2<-pd_text_2 %>% strsplit(split = "\n") # splitting the content to give our data a structure that is closer to the original one
pd_text_2[[1]][1]
pd_text_2[[1]][2]
pd_text_2[[1]][3]
pd_text_2[[1]][4]
pd_text_2[[1]][5]
pd_text_2[[1]][6]
str(pd_text_2)
pd_text_2[[2]]
pd_text_2[[1]]
#using for loop to repeat the process to all 113 pdf files in my directory
corpus_pd <- data.frame(title=c(),text=c())
pdf_text(paste(file_dir,"/",file_vector[1], sep = "")) %>%
strsplit("\n")-> document_text
for (i in 1:length(file_vector)){
pdf_text(paste(file_dir,"/",file_vector[1], sep = "")) %>%
strsplit("\n")-> document_text
data.frame("title" = gsub(x =file_vector[i],pattern = ".pdf", replacement = ""),
"text" = document_text, stringsAsFactors = FALSE) -> document
colnames(document) <- c("company", "text")
corpus_pd <- rbind(corpus_pd,document)
}
colnames(document) <- c("title", "text")
for (i in 1:length(file_vector)){
pdf_text(paste(file_dir,"/",file_vector[1], sep = "")) %>%
strsplit("\n")-> document_text
data.frame("title" = gsub(x =file_vector[i],pattern = ".pdf", replacement = ""),
"text" = document_text, stringsAsFactors = FALSE) -> document
colnames(document) <- c("title", "text")
corpus_pd <- rbind(corpus_pd,document)
}
corpus_pd
#using for loop to repeat the process to all 113 pdf files in my directory
corpus_pd <- data.frame(title=c(),text=c())
corpus_pd
for (i in 1:length(file_vector)){
pdf_text(paste(file_dir,"/",file_vector[1], sep = "")) %>%
strsplit("\n")-> document_text
data.frame("title" = gsub(x =file_vector[i],pattern = ".pdf", replacement = ""),
"text" = document_text, stringsAsFactors = FALSE) -> document
colnames(document) <- c("title", "text")
corpus_pd <- rbind(corpus_pd,document)
}
document_text <- pdf_text(paste(file_dir,"/",file_vector[i], sep = "")) %>% strsplit(split="\n")
for (i in 1:length(file_vector)){
document_text <- pdf_text(paste(file_dir,"/",file_vector[i], sep = "")) %>% strsplit(split="\n")
document <- data.frame(title=gsub(file_vector[i],pattern = ".pdf", replacement = ""), text=document_text)
colnames(document) <- c("title", "text")
corpus_pd <- rbind(corpus_pd,document)
}
length(file_vector)
for (i in 1:length(file_vector)){
document_text <- pdf_text(paste(file_dir,"/",file_vector[i], sep = "")) %>% strsplit(split="\n")
document <- data.frame(title=gsub(file_vector[i],pattern = ".pdf", replacement = ""), text=document_text)
corpus_pd <- rbind(corpus_pd,document)
}
for (i in 1:length(file_vector)){
document_text <- pdf_text(paste(file_dir,"/",file_vector[i], sep = "")) %>% strsplit(split="\n")
corpus_pd <- rbind(corpus_pd,document)
}
for (i in 1:length(file_vector)){
document_text <- pdf_text(paste(file_dir,"/",file_vector[i], sep = "")) %>% strsplit(split="\n")
corpus_pd <- rbind(corpus_pd,document_text)
}
# we need to parse all documents so that it forms a dataframe of two column, one column consist of the identifier, one column is the text parts
length(pd_text_2)
# we need to parse all documents so that it forms a dataframe of two column, one column consist of the identifier, one column is the text parts
length(pd_text_1)
# we need to parse all documents so that it forms a dataframe of two column, one column consist of the identifier, one column is the text parts
type(pd_text_1)
# we need to parse all documents so that it forms a dataframe of two column, one column consist of the identifier, one column is the text parts
typeof(pd_text_1)
# we need to parse all documents so that it forms a dataframe of two column, one column consist of the identifier, one column is the text parts
name(pd_text_1)
# we need to parse all documents so that it forms a dataframe of two column, one column consist of the identifier, one column is the text parts
names(pd_text_1)
# we need to parse all documents so that it forms a dataframe of two column, one column consist of the identifier, one column is the text parts
names(pd_text_1)<-file_vector[1]
names(pd_text_1)
file_vector[1]
names(pd_text_1)[[1]]
names(pd_text_1)[[2]]
names(pd_text_1)[2]
names(pd_text_1)[1]
for (i in 1:length(pd_text_1)){
names(pd_text_1)[i]<-file_vector[1]
}
names(pd_text_1)
# breaking to data.frame
unlist(pd_text_1)
# breaking to data.frame
pd_text_1_df<-data.frame(title=c(), text=c())
for (i in 1:length(pd_text_1)){
text_1_df<-data.frame(title=names(pd_text_1)[i],text=pd_text_1[i])
pd_text_1_df<-rbind(pd_text_1_df,text_1_df)
}
pd_text_1_df
View(pd_text_1_df)
# converting to tidy text
library(tidytext)
file_word<-pd_text_1_df %>% unnest_tokens(word,text)
str(pd_text_1_df)
# breaking to data.frame
pd_text_1_df<-data.frame(title=c(), text=c())
for (i in 1:length(pd_text_1)){
text_1_df<-data.frame(title=names(pd_text_1)[i],text=pd_text_1[i], stringsAsFactors = F)
pd_text_1_df<-rbind(pd_text_1_df,text_1_df)
}
str(pd_text_1_df)
file_word<-pd_text_1_df %>% unnest_tokens(word,text)
for (i in 1:length(pd_text_1)){
text_1_df<-data.frame(title=names(pd_text_1)[i],text=pd_text_1[i])
pd_text_1_df<-rbind(pd_text_1_df,text_1_df)
pd_text_1_df$text<-as.factor(pd_text_1_df)
}
for (i in 1:length(pd_text_1)){
text_1_df<-data.frame(title=names(pd_text_1)[i],text=pd_text_1[i])
pd_text_1_df<-rbind(pd_text_1_df,text_1_df)
}
str(pd_text_1_df)
head(pd_text_1_df)
# breaking to data.frame
pd_text_1_df<-data.frame(title=c(), text=c())
for (i in 1:length(pd_text_1)){
text_1_df<-data.frame(title=names(pd_text_1)[i],text=pd_text_1[i])
pd_text_1_df<-rbind(pd_text_1_df,text_1_df)
}
head(pd_text_1_df)
View(pd_text_1_df)
# breaking to data.frame
pd_text_1_df<-data.frame(title=c(), text=c())
for (i in 1:length(pd_text_1)){
text_1_df<-data.frame(title=names(pd_text_1)[i],content=pd_text_1[i])
pd_text_1_df<-rbind(pd_text_1_df,text_1_df)
}
head(pd_text_1_df)
head(pd_text_1_df)
# breaking to data.frame
pd_text_1_df<-data.frame(title=c(), text=c())
for (i in 1:length(pd_text_1)){
text_1_df<-data.frame("title"=names(pd_text_1)[i],"content"=pd_text_1[i])
pd_text_1_df<-rbind(pd_text_1_df,text_1_df)
}
head(pd_text_1_df)
head(pd_text_1_df)
class(pd_text_1_df)
typeof(pd_text_1_df)
glimpse(pd_text_1_df)
# breaking to data.frame
pd_text_1_df<-data.frame("title"=c(), "content"=c())
for (i in 1:length(pd_text_1)){
text_1_df<-data.frame("title"=names(pd_text_1)[i],"content"=pd_text_1[i])
pd_text_1_df<-rbind(pd_text_1_df,text_1_df)
}
typeof(pd_text_1_df)
glimpse(pd_text_1_df)
# breaking to data.frame
pd_text_1_df<-data.frame("title"=c(), "content"=c())
for (i in 1:length(pd_text_1)){
text_1_df<-data.frame("title"=names(pd_text_1)[i],"content"=pd_text_1[[i]])
pd_text_1_df<-rbind(pd_text_1_df,text_1_df)
}
glimpse(pd_text_1_df)
# breaking to data.frame
pd_text_1_df<-data.frame("title"=c(), "content"=c())
for (i in 1:length(pd_text_1)){
text_1_df<-data.frame("title"=names(pd_text_1)[i],"content"=pd_text_1[[i]])
pd_text_1_df<-rbind(pd_text_1_df,as.characters(text_1_df))
}
# breaking to data.frame
pd_text_1_df<-data.frame("title"=c(), "content"=c())
for (i in 1:length(pd_text_1)){
text_1_df<-data.frame("title"=names(pd_text_1)[i],"content"=pd_text_1[[i]])
pd_text_1_df<-rbind(pd_text_1_df,as.character(text_1_df))
}
glimpse(pd_text_1_df)
# breaking to data.frame
pd_text_1_df<-data.frame("title"=c(), "content"=c())
for (i in 1:length(pd_text_1)){
text_1_df<-data.frame("title"=names(pd_text_1)[i],"content"=as.character(pd_text_1[[i]]))
pd_text_1_df<-rbind(pd_text_1_df,text_1_df)
}
glimpse(pd_text_1_df)
pd_text_1_df$content<-as.character(pd_text_1_df$content)
glimpse(pd_text_1_df)
file_word<-pd_text_1_df %>% unnest_tokens(word,content)
file_word
head(file_word)
View(file_word)
#using for loop to repeat the process to all 113 pdf files in my directory
corpus_pd <- data.frame("title"=c(),"content"=c())
file_df<-data.frame("title"=c(),"content"=c())
for (i in 1:length(file_vector)){
document_text <- pdf_text(paste(file_dir,"/",file_vector[i], sep = "")) %>% strsplit(split="\n")
for (i in 1:length(document_text)){
names(document_text)[i]<-file_vector[i]}
for (i in 1:length(document_text)){
text_df<-data.frame("title"=names(document_text)[i],"content"=document_text[[i]])
file_df<-rbind(file_df,text_df)}
corpus_pd<-rbind(corpus_pd,file_df)
}
for (i in 1:length(file_vector)){
document_text <- pdf_text(paste(file_dir,"/",file_vector[i], sep = "")) %>% strsplit(split="\n")
for (i in 1:length(document_text)){
names(document_text)[i]<-file_vector[i]}
for (i in 1:length(document_text)){
text_df<-data.frame("title"=names(document_text)[i],"content"=document_text[[i]])
file_df<-rbind(file_df,text_df)}
corpus_pd<-rbind(corpus_pd,file_df)
}
View(corpus_pd)
glimpse(corpus_pd)
levels(corpus_pd$title)
file_vector
## Getting all my literature in my folder
file_dir<-c("D:/Master/Thesis/PhylogeneticDiversity/PD_as_response_var") # literature directory
file_vector<-list.files(path=file_dir)
str(file_vector) # I got 113 papers
head(file_vector) # these are just the titles
# breaking to data.frame
pd_text_1_df<-data.frame("title"=c(), "content"=c())
for (i in 1:length(pd_text_1)){
text_1_df<-data.frame("title"=names(pd_text_1)[i],"content"=as.character(pd_text_1[[i]]))
pd_text_1_df<-rbind(pd_text_1_df,text_1_df)
}
glimpse(pd_text_1_df)
for (i in 1:length(pd_text_1)){
text_1_df<-data.frame("title"=names(pd_text_1)[i],"content"=pd_text_1[[i]],stringsAsFactors = F)
pd_text_1_df<-rbind(pd_text_1_df,text_1_df)
}
glimpse(pd_text_1_df)
pd_text_1_df$content<-as.character(pd_text_1_df$content)
glimpse(pd_text_1_df)
#using for loop to repeat the process to all 113 pdf files in my directory
corpus_pd <- data.frame("title"=c(),"content"=c())
file_df<-data.frame("title"=c(),"content"=c())
## the following nested for loops will take a while
for (i in 1:length(file_vector)){
document_text <- pdf_text(paste(file_dir,"/",file_vector[i], sep = "")) %>% strsplit(split="\n")
for (i in 1:length(document_text)){
names(document_text)[i]<-file_vector[i]}
for (i in 1:length(document_text)){
text_df<-data.frame("title"=names(document_text)[i],"content"=document_text[[i]])
file_df<-rbind(file_df,text_df)}
corpus_pd<-rbind(corpus_pd,file_df)
}
glimpse(corpus_pd)
corpus_pd$content<-as.character(corpus_pd$content)
glimpse(corpus_pd)
write.csv(corpus_pd,file="D:\Master\Rcourse\myWebsite\content\post")
write.csv(corpus_pd,file="D:/Master/Rcourse/myWebsite/content/post")
write.csv(corpus_pd,file="D:/Master/Rcourse/myWebsite/content/post/corpus_pd.csv")
corpus_raw<-read.csv("D:/Master/Rcourse/myWebsite/content/post/corpus_pd.csv")
head(corpus_raw)
glimpse(corpus_pd)
corpus_pd_tidy<-corpus_pd %>% unnest_tokens(word,content)
head(corpus_pd_tidy)
glimpse(corpus_pd_tidy)
?read.csv
?write.csv
write.csv(corpus_pd,file="D:/Master/Rcourse/myWebsite/content/post/corpus_pd.csv",row.names = F)
corpus_pd<-read.csv("D:/Master/Rcourse/myWebsite/content/post/corpus_pd.csv")
head(corpus_pd)
glimpse(corpus_pd)
corpus_pd_tidy<-corpus_pd %>% unnest_tokens(word,content)
corpus_pd<-read.csv("D:/Master/Rcourse/myWebsite/content/post/corpus_pd.csv",stringsAsFactors = F)
head(corpus_pd)
str(corpus_pd)
corpus_pd_tidy<-corpus_pd %>% unnest_tokens(word,content)
head(corpus_pd_tidy)
glimpse(corpus_pd_tidy)
corpus_pd %>%
filter(!grepl(c("evolution"),text))
glimpse(corpus_pd)
corpus_pd %>%
filter(grepl(c("evolution"),text))
blogdown::serve_site()
blogdown::serve_site()
getwd*()
getwd()
servr::daemon_stop(1)
blogdown::serve_site()
servr::daemon_stop(1)
blogdown::serve_site()
blogdown::serve_site()
servr::daemon_stop(2)
servr::daemon_stop(3)
?blogdown::hugo_build()
?blogdown::serve_site
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
servr::daemon_stop(4)
servr::daemon_stop(5)
blogdown::hugo_cmd("-v")
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
install.packages("blogdown")
Rprofile.site
.libPaths()
.libPaths("C:/Program Files/R/R-3.6.2/library")
.libPaths()
install.packages("blogdown")
library(blogdown)
.libPaths("C:/Program Files/R/R-3.6.2/library" "C:/Users/sagit/OneDrive/Documents/R/win-library/3.6")
.libPaths("C:/Users/sagit/OneDrive/Documents/R/win-library/3.6")
.libPaths()
library(blogdown)
install.packages("blogdown")
install.packages("blogdown")
library(blogdown)
blogdown::serve_site()
?blogdown
?`blogdown-package`
?blogdown-package
blogdown::update_hugo()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::hugo_version()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::hugo_version()
servr::daemon_stop(1)
blogdown::serve_site()
blogdown::hugo_version()
blogdown::serve_site()
